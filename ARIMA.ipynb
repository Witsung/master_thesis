{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from scipy.stats import boxcox, weibull_min, exponweib, shapiro\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import numpy as np\n",
    "from pmdarima.arima import auto_arima, ARIMA\n",
    "from scipy.special import inv_boxcox\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pred_plot(df, target_col_name='real', pred_start=0, pred_end=50, pred_interval=2, \n",
    "                   xlim_low=0, xlim_up=200, get_errors=True, scale=True):\n",
    "    '''\n",
    "    get a df has ['real', 's1', 's2', ...] in columns to make plot\n",
    "    '''\n",
    "\n",
    "    \n",
    "    pred_steps = len(df.drop(columns=target_col_name).columns)\n",
    "    print(\"pred_steps: {}\".format(pred_steps))\n",
    "    def evaluate_pred(df, target_col_name):\n",
    "\n",
    "        \n",
    "        real = np.array([df.real[i:pred_steps+i].values for i in range(len(df)-pred_steps + 1 )])\n",
    "\n",
    "        preds = df.drop(columns=target_col_name).values[:len(df)-pred_steps+1,:]\n",
    "        errors = real - preds\n",
    "\n",
    "        rmse = (np.mean(errors**2)*pred_steps)**(1/2)\n",
    "        mae = np.mean(abs(errors))*pred_steps\n",
    "        print('RMSE: {}'.format(rmse))\n",
    "        print('MAE: {}'.format(mae))\n",
    "        return errors\n",
    "    \n",
    "    errors = evaluate_pred(df, target_col_name=target_col_name)    \n",
    "    \n",
    "    if scale:\n",
    "        ss = StandardScaler()\n",
    "        df = pd.DataFrame(ss.fit_transform(df), columns=df.columns)\n",
    "    \n",
    "    fig = figure(num=None, figsize=(20, 6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(df[target_col_name], 'g')\n",
    "\n",
    "    for pred_count in range(pred_start, pred_end, pred_interval):\n",
    "        ax.plot([None for i in range(pred_count)] + list(df.drop(columns=target_col_name).iloc[pred_count,:].values), \n",
    "                'r--.', linewidth=0.5)\n",
    "\n",
    "    ax.legend(['real','predicted'], prop={'size':15})\n",
    "    ax.set_xlim(xlim_low, xlim_up)\n",
    "    ax.set_xlabel('Step')\n",
    "    if scale:\n",
    "        ax.set_ylabel('Scaled_wind_speed')\n",
    "    else:\n",
    "        ax.set_ylabel('Wind_speed')\n",
    "    plt.show()\n",
    "    if get_errors:\n",
    "        return fig, ax, errors\n",
    "    else:\n",
    "        return fig, ax\n",
    "\n",
    "def grid_search(df_fit, order_list):\n",
    "    for i, o in enumerate(order_list):\n",
    "        try:\n",
    "            model = ARIMA(order=o, method='css-mle')\n",
    "            model_fit = model.fit(y = df_fit.values.flatten())\n",
    "            if i == 0:\n",
    "                best_aicc = model_fit.aicc()\n",
    "                best_order = o\n",
    "\n",
    "            elif best_aicc > model_fit.aicc():\n",
    "                best_aicc = model_fit.aicc()\n",
    "                best_order = o\n",
    "        except:\n",
    "            pass\n",
    "        print('order:{}, aicc:{}, bic:{}'.format(o, model_fit.aicc(), model_fit.bic()))\n",
    "    return best_order\n",
    "\n",
    "def make_init_visual(series, show_acf=False):\n",
    "#     fig = plt.figure(constrained_layout=True, figsize=(10, 8))\n",
    "#     gs = fig.add_gridspec(2, 2)\n",
    "#     ax1 = fig.add_subplot(gs[0, :])\n",
    "#     ax2 = fig.add_subplot(gs[1, 0])\n",
    "#     ax3 = fig.add_subplot(gs[1, 1])\n",
    "    \n",
    "#     ax1.plot(series, 'c', linewidth=0.8)\n",
    "#     ax1.set_xlabel('Second', fontsize=12)\n",
    "#     ax1.set_ylabel('Wind_speed', fontsize=12)\n",
    "#     ax2.hist(series, bins=30)\n",
    "#     ax2.set_xlabel('Wind_speed', fontsize=12)\n",
    "#     ax3 = qqplot(series, line='q', ax = ax3)\n",
    "    \n",
    "    fig = plt.figure(constrained_layout=True, figsize=(10, 3))\n",
    "    gs = fig.add_gridspec(1, 2)\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    \n",
    "    ax1.hist(series, bins=30)\n",
    "    ax1.set_xlabel('Scaled_wind_speed (m/s)', fontsize=12)\n",
    "    ax2 = qqplot(series, line='q', ax = ax2)\n",
    "    \n",
    "    t, p = shapiro(series)\n",
    "    print(\"Shapiro_test_statistic:{}, p_value:{}\".format(t, p))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and plot\n",
    "df = pd.read_csv('data/v_hub_filt.csv')\n",
    "\n",
    "fig = plt.figure(figsize=(20, 5))\n",
    "plt.plot(df.v_hub_filt, 'c', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "split_point = int(len(df)*0.8)\n",
    "\n",
    "df_train = df.v_hub_filt[:split_point]\n",
    "df_test = df.v_hub_filt[split_point:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_init_visual(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxcox transformation\n",
    "l = boxcox(df_train)[1]\n",
    "print('boxcox_lambda:{}'.format(l))\n",
    "df_train = boxcox(df_train)[0]\n",
    "fig = make_init_visual(df_train)\n",
    "df_train = pd.DataFrame(df_train)\n",
    "# fig.savefig('thesis/figures/ARIMA_boxcox_trans.eps', format='eps', dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_acf(df_train.diff().dropna(), lags=60, alpha=0.05)\n",
    "# plt.savefig('thesis/figures/acf.eps', format='eps', dpi=1200)\n",
    "\n",
    "\n",
    "fig = plot_pacf(df_train.diff().dropna(), lags=60, alpha=0.05)\n",
    "# plt.savefig('thesis/figures/pacf.eps', format='eps', dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 5))\n",
    "plt.plot(df_train.diff().dropna(), 'c', linewidth=0.5)\n",
    "plt.xlabel('Second', fontsize=12)\n",
    "plt.ylabel('Differenced_wind_speed (m/s)', fontsize=12)\n",
    "# plt.savefig('thesis/figures/differenced_wind_speed.eps', format='eps', dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adfuller(df_train.diff().dropna().values.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find best ARIMA(p, d, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_ARIMA = auto_arima(df_train, start_p=13, start_q=0, max_p=16, max_q=1, m=1,\n",
    "                        seasonal=False, trace=True, d=2, max_order=None,\n",
    "                        suppress_warnings=True, error_action=\"ignore\",\n",
    "                        stepwise=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(df_fit, order_list, exogenous):\n",
    "    for i, o in enumerate(order_list):\n",
    "        try:\n",
    "            if i == 0:\n",
    "                best_aicc = model_fit.aicc()\n",
    "                best_order = o\n",
    "\n",
    "            elif best_aicc > model_fit.aicc():\n",
    "                best_aicc = model_fit.aicc()\n",
    "                best_order = o\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        print('order:{}, aicc:{}, bic:{}'.format(o, model_fit.aicc(), model_fit.bic()))\n",
    "    return best_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "model = ARIMA(endog = df_train.values.flatten(), exog=exogenous, order=[1, 1, 1])\n",
    "model_fit = model.fit(disp=0)\n",
    "# model_fit = model.fit(endog = df_train.values.flatten(), exog=exogenous)\n",
    "# print('aicc:{}, bic:{}'.format(model_fit.aicc(), model_fit.bic()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit.aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exogenous=df.vdir_hub[:split_point].values.reshape(-1,1)\n",
    "p_list = np.arange(10,11).tolist()\n",
    "q_list = np.arange(0,2).tolist()\n",
    "d = 1\n",
    "# # orders = [(p, d, q) for p in p_list for q in q_list]\n",
    "# q = 1\n",
    "orders = [(p, d, q) for p in p_list for q in q_list]\n",
    "orders\n",
    "grid_search(df_train, [1, 1, 0], exogenous=exogenous)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exogenous=df.vdir_hub[:split_point].values.reshape(-1,1)\n",
    "model = ARIMA(order=(12,1,1), method='mle', maxiter=100)\n",
    "model_fit = model.fit(y = df_train.values.flatten(), exogenous=exogenous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnose_plot = model_fit.plot_diagnostics(figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "exogenous_test = df.vdir_hub[split_point:].values.reshape(-1,1)\n",
    "preds = []\n",
    "for i, v in enumerate(df_test.values):\n",
    "    if i == 0:\n",
    "        pred = model_fit.predict(5, exogenous=np.repeat(df.vdir_hub[:split_point].values[-1], 5).reshape(-1,1))\n",
    "    else:\n",
    "        pred = model_fit.predict(5, exogenous=np.repeat(exogenous_test[i-1],5).reshape(-1,1))\n",
    "    pred = inv_boxcox(pred, l)\n",
    "    preds.append(pred)\n",
    "    new_observation = boxcox(v, l)\n",
    "    model_fit.add_new_observations(y=np.array(new_observation).reshape(1,), \n",
    "                                   exogenous=exogenous_test[i].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pred = {'s{}'.format(i+1):list(np.array(preds)[:,i]) for i in range(np.array(preds).shape[1])}\n",
    "dict_pred['real'] = list(df_test.values)\n",
    "df_pred = pd.DataFrame.from_dict(dict_pred)\n",
    "fig, ax, arimax_error = make_pred_plot(df_pred.dropna(), target_col_name='real', pred_start=900, \n",
    "                                       pred_end=1000, pred_interval=2, xlim_low=900, xlim_up=1000,\n",
    "                                       scale=True)\n",
    "ax.set_title('ARIMA')\n",
    "ax.set_ylim(0,4)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('arimax_error', arimax_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.set_title('')\n",
    "ax.set_ylim(-1,3)\n",
    "fig\n",
    "fig.savefig('thesis/figures/ARIMA_result.eps', format='eps', dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StandardScaler"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
